{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 13:28:23.602003: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import colorsys\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from glob import glob\n",
    "from openvino.runtime import Core\n",
    "from tensorflow import reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions were based on the [OAKarrange](https://github.com/cidimec/UCB-squirrels/blob/main/datasets_utils/OAKarrange.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLimits(frame):\n",
    "    ''' Let's find the red objects in the scene ''' \n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    h,_,_ = cv2.split(hsv_frame)\n",
    "    lower_red = np.array([0,150,150])\n",
    "    upper_red = np.array([20,255,255])\n",
    "    red = cv2.inRange(hsv_frame, lower_red, upper_red)\n",
    "    red = cv2.bitwise_not(red)\n",
    "    \n",
    "    # Finding the possition of the two red marks in the scene\n",
    "    keypoints = detector2.detect(red)\n",
    "    marks = []\n",
    "    copied_im = cv2.cvtColor(red.copy(), cv2.COLOR_GRAY2BGR)\n",
    "    for k in keypoints:\n",
    "        x, y = k.pt\n",
    "        marks.append((int(x), int(y)))\n",
    "    return marks\n",
    "\n",
    "def isEmpty(scene):\n",
    "    ''' Checks if in the current frame there is someone using the histogram of a blank laboratory '''\n",
    "    hsv_scene = cv2.cvtColor(scene,cv2.COLOR_BGR2HSV)\n",
    "    H, S, V = cv2.split(hsv_scene)\n",
    "    H_array = H[S > 100].flatten()\n",
    "    val, pos = np.histogram(H_array, 18)\n",
    "    val[[0,3]] = 0\n",
    "#     print(val[[4,5,7,8,12,13,14,15,16]].max())\n",
    "    return val.max()<1000\n",
    "\n",
    "def create_dir(folder, force=True, verbose=False):\n",
    "    '''   Create a directory if it doesn't exist  '''\n",
    "    try:\n",
    "        os.makedirs(folder)\n",
    "        if verbose: print('Directory {} created succesfully.'.format(folder))   \n",
    "    except:\n",
    "        if force:\n",
    "            if verbose: print('{} already exists. Creating a new one'.format(folder))\n",
    "            shutil.rmtree(folder)\n",
    "            os.makedirs(folder)\n",
    "        else:\n",
    "            if verbose: print('{} already exists.'.format(folder))\n",
    "            pass\n",
    "\n",
    "def bkgrd_hsv_substraction(frgrd, bkgrd):\n",
    "    ''' Performs background substraction using the HLS color space '''\n",
    "    bkgrd_hsv = cv2.cvtColor(bkgrd, cv2.COLOR_BGR2HLS)\n",
    "    frgrd_hsv = cv2.cvtColor(frgrd, cv2.COLOR_BGR2HLS)\n",
    "\n",
    "    diff = cv2.subtract(bkgrd_hsv, frgrd_hsv)\n",
    "    diff_gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    _, raw = cv2.threshold(diff_gray, 15, 255, cv2.THRESH_BINARY)\n",
    "    if diff_gray.sum()> 400000:\n",
    "        closed = fine_mask(raw)\n",
    "        blured = cv2.GaussianBlur(closed,(3,3),0)\n",
    "        return True, raw, closed, blured\n",
    "    else:\n",
    "        return False, None, None, None\n",
    "\n",
    "def isBackground(frgnd, bkgnd, th=1):\n",
    "    bkgrd_hsv = cv2.cvtColor(bkgnd, cv2.COLOR_BGR2Lab)\n",
    "    frgrd_hsv = cv2.cvtColor(frgnd, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "    diff = cv2.subtract(bkgrd_hsv, frgrd_hsv)\n",
    "    diff_gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    return diff.sum() / 1000000\n",
    "\n",
    "def com_his(frame, background, th=5):\n",
    "    hsv_scene = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    H, S, V = cv2.split(hsv_scene)\n",
    "    H_array = H[S > 100].flatten()\n",
    "    val1, pos = np.histogram(H_array, 18)\n",
    "#     print(val1)\n",
    "\n",
    "    hsv_scene = cv2.cvtColor(background,cv2.COLOR_BGR2HSV)\n",
    "    H, S, V = cv2.split(hsv_scene)\n",
    "    H_array = H[S > 100].flatten()\n",
    "    val2, pos = np.histogram(H_array, 18)\n",
    "#     print(val2)\n",
    "    return np.linalg.norm(val2 - val1) //1000 > th\n",
    "\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "def bkgrd_Lab_substraction(frame, background, th=5):\n",
    "    ''' Performs background substraction using the Lab color space, which helps to reduce light noise '''\n",
    "    bkgrd_h = (cv2.cvtColor(background, cv2.COLOR_BGR2Lab))\n",
    "    frgrd_h = (cv2.cvtColor(frame, cv2.COLOR_BGR2Lab))\n",
    "\n",
    "    diff = cv2.subtract(bkgrd_h, frgrd_h)\n",
    "    diff = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    _, diff = cv2.threshold(diff, 5, 255, cv2.THRESH_BINARY)\n",
    "    diff = cv2.morphologyEx(diff, cv2.MORPH_CLOSE, kernel)\n",
    "    if diff.sum() / 1000000 > th:\n",
    "        closed = fine_mask(diff)\n",
    "        blured = cv2.GaussianBlur(closed,(3,3),0)\n",
    "        closed = cv2.multiply(diff, closed)\n",
    "        return True, diff, closed, blured\n",
    "    else:\n",
    "        return False, None, None, None\n",
    "    \n",
    "def fine_mask(mask):\n",
    "    ''' Takes a raw mask as input and returns the biggest contour mask '''\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    c = max(contours, key = cv2.contourArea)\n",
    "    out = np.zeros_like(mask)\n",
    "    out = cv2.drawContours(out, [c], 0, 255, -1)\n",
    "    return out\n",
    "\n",
    "\n",
    "def random_colors(N, bright=True):\n",
    "    ''' Generate random colors  '''\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    # random.shuffle(colors)\n",
    "    return colors\n",
    "\n",
    "color = random_colors(1)[0]\n",
    "\n",
    "def apply_mask(frame, mask, color, alpha=0.5):\n",
    "    ''' Apply the given mask to the image '''\n",
    "    image = frame.copy()\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['008', '009', '010', '011', '012', '013', '014', '015', '016']\n"
     ]
    }
   ],
   "source": [
    "images_dir = '/home/christian/Documents/Datasets/OakGait16/frames/'\n",
    "clips_directory = '/home/christian/Documents/Datasets/OakGait16/clips'\n",
    "frs_dir = 'rgb_segmentation/'\n",
    "mks_dir = 'masks/'\n",
    "verbose = True\n",
    "#subjects = sorted(os.listdir(os.path.join(clips_directory, '105')))\n",
    "subjects = ['008', '009', '010', '011', '012', '013', '014', '015', '016']\n",
    "nclips = {'nm':3, 'bg':3, 'cl':3}\n",
    "\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING VIEW: 120\n",
      "Processing subject: 008 view: 120....                                  \n",
      "Processing subject: 009 view: 120....                                  n/008/cl/cl-03\n",
      "Processing subject: 010 view: 120....                                  n/009/cl/cl-03\n",
      "Processing subject: 011 view: 120....                                  n/010/cl/cl-03\n",
      "Processing subject: 012 view: 120....                                  n/011/cl/cl-03\n",
      "Processing subject: 013 view: 120....                                  n/012/cl/cl-03\n",
      "Processing subject: 014 view: 120....                                  n/013/cl/cl-03\n",
      "Processing subject: 015 view: 120....                                  n/014/cl/cl-03\n",
      "Processing subject: 016 view: 120....                                  n/015/cl/cl-03\n",
      "/home/christian/Documents/Datasets/OakGait16/frames/120/rgb_segmentation/016/cl/cl-03"
     ]
    }
   ],
   "source": [
    "views = ['120']\n",
    "for view in views:\n",
    "    frames_dir = os.path.join(images_dir, view, frs_dir)\n",
    "    masks_dir = os.path.join(images_dir, view, mks_dir)\n",
    "    print(f'PROCESSING VIEW: {view}')\n",
    "#     subjects = sorted(os.listdir(os.path.join(clips_directory, view)))\n",
    "    for subject in subjects:\n",
    "#     for subject in ['004']:\n",
    "        print(f'Processing subject: {subject} view: {view}....                                  ')\n",
    "        create_dir(os.path.join(frames_dir, subject), force=True)\n",
    "        create_dir(os.path.join(masks_dir, subject), force=True)\n",
    "\n",
    "        subject_dir = os.path.join(clips_directory, view, subject)\n",
    "        walks = os.listdir(subject_dir)\n",
    "        \n",
    "        for j, walk in enumerate(['nm', 'bg', 'cl']):\n",
    "#         for j, walk in enumerate(['nm']):\n",
    "\n",
    "            walk_dir = os.path.join(subject_dir, walk)\n",
    "            background = cv2.imread(os.path.join(walk_dir, f'background.png'))\n",
    "            clips = sorted(os.listdir(walk_dir))\n",
    "            \n",
    "            save_back_path = os.path.join(frames_dir, subject, f'{walk}-background.png')\n",
    "            cv2.imwrite(save_back_path, background)\n",
    "            \n",
    "            for i, clip in enumerate(clips):\n",
    "                if clip[-4:] == '.avi' and nclips[walk]>=i:\n",
    "                    clip_path = os.path.join(walk_dir, clip)\n",
    "                    sub_dir = os.path.join(frames_dir, subject, walk, clip.split('.')[0])\n",
    "                    mask_dir = os.path.join(masks_dir, subject, walk, clip.split('.')[0])\n",
    "                    create_dir(sub_dir, force=True)\n",
    "                    create_dir(mask_dir, force=True)\n",
    "                    print(sub_dir, end='\\r')\n",
    "                    cap = cv2.VideoCapture(clip_path)\n",
    "                    cnt = 0\n",
    "                    while True:\n",
    "                        ret, frame = cap.read()\n",
    "                        if ret:\n",
    "                            try:\n",
    "                                ok, diff_gray, closed, blured = bkgrd_Lab_substraction(frame, background)\n",
    "                                if ok:\n",
    "                                    cnt +=1\n",
    "                                    frame_path = f'{sub_dir}/{str(cnt).zfill(4)}.jpg'\n",
    "                                    mask_path = f'{mask_dir}/{str(cnt).zfill(4)}.jpg'\n",
    "                                    frame = cv2.resize(frame, (960,540), interpolation=cv2.INTER_AREA)\n",
    "                                    closed = cv2.resize(closed, (960,540), interpolation=cv2.INTER_AREA)\n",
    "                                    #print(np.mean(closed[:540//2+30,:]), str(cnt).zfill(4))\n",
    "                                    if np.mean(closed[:540//2+30,:])>7:\n",
    "                                        cv2.imwrite(frame_path, frame)\n",
    "                                        cv2.imwrite(mask_path, closed)\n",
    "                                    if verbose:\n",
    "                                        masked = apply_mask(frame.copy(), closed.astype('bool'), color)\n",
    "    #                                    ok, diff_gray, closed, blured = bkgrd_Lab_substraction(frame, background)\n",
    "                                if ok:\n",
    "                                    cnt +=1\n",
    "                                    frame_path = f'{sub_dir}/{str(cnt).zfill(4)}.jpg'\n",
    "                                    mask_path = f'{mask_dir}/{str(cnt).zfill(4)}.jpg'\n",
    "                                    frame = cv2.resize(frame, (960,540), interpolation=cv2.INTER_AREA)\n",
    "                                    closed = cv2.resize(closed, (960,540), interpolation=cv2.INTER_AREA)\n",
    "                                    #print(np.mean(closed[:540//2+30,:]), str(cnt).zfill(4))\n",
    "                                    if np.mean(closed[:540//2+30,:])>6:\n",
    "                                        cv2.imwrite(frame_path, frame)\n",
    "                                        cv2.imwrite(mask_path, closed)\n",
    "                                    if verbose:\n",
    "                                        masked = apply_mask(frame.copy(), closed.astype('bool'), color)\n",
    "    #                                     cv2.imshow('frame', masked)     cv2.imshow('frame', masked)\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            break\n",
    "                        if cv2.waitKey(1) == ord('q'):\n",
    "                            break\n",
    "                    cap.release()\n",
    "    print('', end=\"\\r\")\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "device = \"CPU\"\n",
    "model = ie.read_model(model=\"models/public/mobilenet-ssd/FP32/mobilenet-ssd.xml\")\n",
    "compiled_model = ie.compile_model(model=model, device_name=device)\n",
    "input_layer_ir = next(iter(compiled_model.inputs))\n",
    "output_layer_ir = next(iter(compiled_model.outputs))\n",
    "\n",
    "def find_ROI(img):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        input_image = cv2.dnn.blobFromImage(img, size=(300, 300), ddepth=cv2.CV_8U)\n",
    "\n",
    "        input_image = reshape(input_image, [-1,3,300,300])\n",
    "        result = compiled_model.infer_new_request({0: input_image})\n",
    "\n",
    "        x_min = next(iter(result.values()))[:,:,np.where(next(iter(result.values()))[0,0,:,1] == 15.),3]*300\n",
    "        y_min = next(iter(result.values()))[:,:,np.where(next(iter(result.values()))[0,0,:,1] == 15.),4]*300\n",
    "        x_max = next(iter(result.values()))[:,:,np.where(next(iter(result.values()))[0,0,:,1] == 15.),5]*300\n",
    "        y_max = next(iter(result.values()))[:,:,np.where(next(iter(result.values()))[0,0,:,1] == 15.),6]*300\n",
    "\n",
    "        (x, y, w, h) = int(x_min), int(y_min), int(x_max), int(y_max)\n",
    "\n",
    "        offsets = [10, 10, 10, 10]\n",
    "        x = x - offsets[0] if x - offsets[0] >=0 else 0\n",
    "        y = y - offsets[3] if y - offsets[3] >=0 else 0\n",
    "        w = w + offsets[1]+offsets[0] if w + offsets[1]+offsets[0] <=300 else 300\n",
    "        h = h + offsets[3]+offsets[1] if h + offsets[3]+offsets[1] <=300 else 300\n",
    "\n",
    "        \n",
    "        return x,y,w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/home/christian/Documents/Datasets/OakGait16/frames/'\n",
    "rois_dir = '/home/christian/Documents/Datasets/OakGait16/rois/'\n",
    "gt_rois_dir = '/home/christian/Documents/Datasets/OakGait16/gt_rois/'\n",
    "frs_dir = 'rgb_segmentation/'\n",
    "mks_dir = 'masks/'\n",
    "views = ['060','075','090','105','120']\n",
    "training_silhouettes = '/home/christian/Documents/Datasets/OakGait16/rgb_silhouettes/'\n",
    "masked_silhouettes = '/home/christian/Documents/Datasets/OakGait16/masked_silhouettes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING GAIT REPRESENTATIONS FROM VIEW: 060\n",
      "Processing subject: 000 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 13:28:42.308712: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-26 13:28:42.343292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 13:28:42.344236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce 940MX computeCapability: 5.0\n",
      "coreClock: 1.2415GHz coreCount: 3 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 14.30GiB/s\n",
      "2022-08-26 13:28:42.344285: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-08-26 13:28:42.677824: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-08-26 13:28:42.677957: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-08-26 13:28:42.717216: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-26 13:28:42.875073: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-26 13:28:42.875449: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/christian/intel/openvino_2022.1.0.643/extras/opencv/python/cv2/../../bin:/home/christian/intel/openvino_2022/extras/opencv/lib:/home/christian/intel/openvino_2022/tools/compile_tool:/home/christian/intel/openvino_2022/runtime/3rdparty/tbb/lib::/home/christian/intel/openvino_2022/runtime/3rdparty/hddl/lib:/home/christian/intel/openvino_2022/runtime/lib/intel64:/usr/local/cuda/lib64\n",
      "2022-08-26 13:28:42.942985: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-08-26 13:28:42.965323: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-08-26 13:28:42.965368: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-08-26 13:28:42.965806: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-26 13:28:42.966391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-26 13:28:42.966419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ['bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 001 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 002 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 003 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 004 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 005 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 006 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 007 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 008 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 009 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 010 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 011 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 012 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 013 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 014 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 015 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 016 view: 060\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "GENERATING GAIT REPRESENTATIONS FROM VIEW: 075\n",
      "Processing subject: 000 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 001 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 002 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 003 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 004 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 005 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 006 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 007 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 008 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 009 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 010 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 011 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 012 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 013 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 014 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 015 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "Processing subject: 016 view: 075\n",
      "Processing: ['nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02']\n",
      "Processing: ['cl-01', 'cl-02']\n",
      "GENERATING GAIT REPRESENTATIONS FROM VIEW: 090\n",
      "Processing subject: 000 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 001 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 002 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 003 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 004 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 005 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 006 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 007 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 008 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 009 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 010 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 011 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 012 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 013 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 014 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 015 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 016 view: 090\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "GENERATING GAIT REPRESENTATIONS FROM VIEW: 105\n",
      "Processing subject: 000 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 001 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 002 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 003 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 004 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 005 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 006 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 007 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 008 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 009 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 010 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 011 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 012 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 013 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 014 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 015 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 016 view: 105\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "GENERATING GAIT REPRESENTATIONS FROM VIEW: 120\n",
      "Processing subject: 000 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 001 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 002 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 003 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 004 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 005 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 006 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 007 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 008 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 009 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 010 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 011 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 012 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 013 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 014 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 015 view: 120\n",
      "Processing: ['nm-01', 'nm-02', 'nm-03']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n",
      "Processing subject: 016 view: 120\n",
      "Processing: ['bn-06', 'nm-01', 'nm-02']\n",
      "Processing: ['bg-01', 'bg-02', 'bg-03']\n",
      "Processing: ['cl-01', 'cl-02', 'cl-03']\n"
     ]
    }
   ],
   "source": [
    "create_dir(training_silhouettes, force=True)\n",
    "create_dir(masked_silhouettes, force=True)\n",
    "for view in views:\n",
    "    frames_dir = os.path.join(images_dir, view, frs_dir)\n",
    "    masks_dir = os.path.join(images_dir, view, mks_dir)\n",
    "    rep_dir = os.path.join(rois_dir, view)\n",
    "    gt_dir = os.path.join(gt_rois_dir, view)\n",
    "    print(f'GENERATING GAIT REPRESENTATIONS FROM VIEW: {view}')\n",
    "    subjects = sorted(os.listdir(os.path.join(images_dir, view, frs_dir)))\n",
    "    c = 0\n",
    "    for subject in subjects:\n",
    "#     for subject in ['022', '023', '025']:\n",
    "        print(f'Processing subject: {subject} view: {view}')\n",
    "        \n",
    "\n",
    "        for j, walk in enumerate(['nm','bg','cl']):\n",
    "#         for j, walk in enumerate(['nm']):\n",
    "            seq_dir = os.path.join(frames_dir, subject, walk)\n",
    "            seqs = sorted(os.listdir(seq_dir))\n",
    "            \n",
    "            print(f'Processing: {seqs}')\n",
    "            for s, seq in enumerate(seqs):\n",
    "\n",
    "                seq_frames_dir = os.path.join(seq_dir, seq)\n",
    "                lfiles = sorted(os.listdir(seq_frames_dir))\n",
    "                cnt = 0\n",
    "                for idimg, path in enumerate(lfiles):\n",
    "                    \n",
    "                    \n",
    "                        img = cv2.imread(os.path.join(seq_frames_dir, path))\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                        img = cv2.resize(img,(300,300))\n",
    "                        mask = cv2.imread(os.path.join(masks_dir, subject, walk, seq, path),0)\n",
    "                        mask = cv2.resize(mask,(300,300))\n",
    "\n",
    "\n",
    "                        try: \n",
    "                            x,y,w,h = find_ROI(img)\n",
    "                            bbox =  [x, y, w, h]\n",
    "                            gti = mask[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "                            roi = cv2.cvtColor(img[bbox[1]:bbox[3], bbox[0]:bbox[2]], cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                            gti_path = os.path.join(masked_silhouettes, f'{subject}-{seq}-{c}.jpg')\n",
    "                            roi_path = os.path.join(training_silhouettes, f'{subject}-{seq}-{c}.jpg')\n",
    "\n",
    "                            cv2.imwrite(gti_path, cv2.resize(gti, (128,128), interpolation=cv2.INTER_AREA))\n",
    "                            cv2.imwrite(roi_path, cv2.resize(roi, (128,128), interpolation=cv2.INTER_AREA))\n",
    "                            c += 1\n",
    "                            \n",
    "                        except:\n",
    "                            pass           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/christian/Documents/CNN-Gait-Recognition-Offline/create_segmentation_dataset.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/christian/Documents/CNN-Gait-Recognition-Offline/create_segmentation_dataset.ipynb#ch0000009?line=0'>1</a>\u001b[0m create_dir(training_silhouettes, force\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/christian/Documents/CNN-Gait-Recognition-Offline/create_segmentation_dataset.ipynb#ch0000009?line=1'>2</a>\u001b[0m create_dir(masked_silhouettes, force\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/christian/Documents/CNN-Gait-Recognition-Offline/create_segmentation_dataset.ipynb#ch0000009?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m view \u001b[39min\u001b[39;00m views:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_dir' is not defined"
     ]
    }
   ],
   "source": [
    "create_dir(training_silhouettes, force=True)\n",
    "create_dir(masked_silhouettes, force=True)\n",
    "\n",
    "for view in views:\n",
    "    frames_dir = os.path.join(images_dir, view, frs_dir)\n",
    "    rep_dir = os.path.join(rois_dir, view)\n",
    "    gt_dir = os.path.join(gt_rois_dir, view)\n",
    "    print(f'SHOWING VIEW: {view}')\n",
    "    subjects = sorted(os.listdir(frames_dir))\n",
    "    for subject in subjects:\n",
    "#     for subject in ['023']:\n",
    "        print(f'Showing subject: {subject} view: {view}')\n",
    "        for j, walk in enumerate(['nm','bg','cl']):\n",
    "#         for j, walk in enumerate(['nm']):\n",
    "            seq_dir = os.path.join(frames_dir, subject, walk)\n",
    "            seqs = sorted(os.listdir(seq_dir))\n",
    "            for s, seq in enumerate(seqs):\n",
    "                sub_roi_dir = os.path.join(rep_dir, subject, walk, seq) \n",
    "                sub_gt_dir = os.path.join(gt_dir, subject, walk, seq) \n",
    "                c = 0\n",
    "                for img in os.listdir(sub_roi_dir):\n",
    "                    rgb_name = os.path.join(sub_roi_dir,img)\n",
    "                    gt_name = os.path.join(sub_gt_dir,img)\n",
    "\n",
    "                    rgb = cv2.imread(rgb_name)\n",
    "                    mask = cv2.imread(gt_name)\n",
    "                    rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)              \n",
    "                    #print(os.path.join(masked_silhouettes, f'{subject}-{seq}-{c}.png'))\n",
    "                    cv2.imwrite(os.path.join(masked_silhouettes, f'{subject}-{seq}-{c}.png'), cv2.resize(mask, (128,128)))\n",
    "                    cv2.imwrite(os.path.join(training_silhouettes, f'{subject}-{seq}-{c}.png'),  cv2.resize(mask, (128,128)))\n",
    "                    c += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('openvino')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e29a5cb2b1ebb6a1291bd733c6cfecfe5f45aa900586811e87b0b788aff8bad7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
